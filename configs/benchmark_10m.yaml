# 10M vector benchmark configuration
dataset_size: 10000000
query_count: 100000
dataset_path: null  # Use synthetic data

dataset_generation:
  enabled: true
  dimension: 256  # Higher dimensionality for more realistic scenario
  clusters: 1000
  cluster_std: 0.12
  k_neighbors: 100
  seed: 42
  # Memory management - configure chunk sizes for large datasets
  chunk_size: 50000  # Larger chunks for 10M dataset (default: 10000)
  query_chunk_size: 5000  # Larger chunks for queries (default: 1000)
  # Ground truth computation - conservative for 4GB RAM
  gt_train_block_size: 25000  # 25K vectors = 25MB training + 200MB distance matrix
  gt_query_block_size: 100  # 100 queries = 100KB + manageable distance matrix

concurrent_inserters: 0
concurrent_searchers: 20
search_batch_size: 75
insert_batch_size: 5000
max_runtime_seconds: 900  # 15 minutes